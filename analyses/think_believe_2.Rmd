---
title: "Think Believe 2 (free response)"
output: 
  html_notebook:
    toc: true
    toc_float: true
---

```{r setup}
knitr::opts_chunk$set(echo = F, message = F)
```

In this notebook we analyze the second "think/believe" task, in which participants completed a series of fill-in-the-blanks with free responses.


```{r}
source("./scripts/dependencies.R")
source("./scripts/custom_funs.R")
source("./scripts/var_recode_contrast.R")
source("./scripts/data_prep.R")
```

Note: We have used a combination of automatic "lemmatization" and hand-coding to do our best to code whether responses should count as "believe" (e.g., including obvious cases like "believes" and "believed"; including Bislama "belif" and "bilif" and other spellings).

We provide two versions of these variables -- one that only includes responses that are strictly "believe" and one that also includes cases that involve the word "believe" (e.g., "firmly believes," "does not believe") -- and likewise for think. The looser interpretations are called `believeX` (or "belief\*") and `thinkX` (or "think\*"). These looser interpretations are the variables that are the focus of the current analyses.


# Overview

From the preregistration:

> "Our overarching hypothesis for the present study is that [...] other languages will have an epistemic verb that is more likely to be used for religious attitude reports (similar to English “believe”) and a different epistemic verb that is more likely to be used for matter-of-fact attitude reports (similar to English “think”). 
> 
> For this study, we are examining five languages in five regions of interest: (i) Mandarin in China; (ii) Thai in Thailand; (iii) Bislama (an English-based creole
language) on the Melanesian Island of Vanuatu; (iv) Fante in Ghana; and (v) American English in the Bay Area, California. 
> 
> We thus have five more specific sub-hypotheses. For each of the first four languages / regions of interest, we hypothesize that a set of words or phrases exists whose usage parallels the difference between usage of “think” and “believe” in American English, with one word or phrase (the “think” analogue) being used for more matter-of-fact attitude reports and the other (the “believe” analogue) being more likely to be used for religious attitude reports. That gives us our first four sub-hypotheses: that Mandarin, Thai, Bislama and Fante speakers will each use two different words in a manner parallel to the use of
“think” and “believe” in an American English setting as identified by Heiphetz, Landers, and Van Leeuwen. Our fifth sub-hypothesis is that the Bay Area portion of the study will replicate the results of the earlier study of Heiphetz, Landers, and Van Leeuwen."


<p style="color:darkred">**SUMMARY: We replicated the original finding in the US (and the findings of Think Believe 1): participants were more likely to write in "believe" for religious than fact questions. We found the same pattern in all five countries/langauges included in this study.**</p>

<p style="color:darkred">**As in Think Believe 1, the pattern was somewhat weaker in Ghana/Fante than in other countries/languages. In Think Believe 1, the pattern was stronger in Thailand/Thai (and no stronger or weaker in China/Mandarin or Vanuatu/Bislama); in contrast, in this study it was stronger in China/Mandarin, weaker in Vanuatu/Bislama, and no stronger or weaker Thailand/Thai. We suspect these patterns are largely accounted for by the fact that so few participants in Ghana and especially Vanuatu spontaneously used the word "believe" in their free responses.**</p>


# Samples

Before we begin, it's important to note that we had unequal sample sizes by country:

```{r}
d2_raw %>% count(thb2_ctry) %>% janitor::adorn_totals()
```

However, `r d2_raw %>% filter(thb2_ordr == "No") %>% count() %>% as.numeric()` participants completed this task after completing other surveys, and an additional `r d2_raw %>% filter(thb2_ordr == "Yes", thb2_attn == "Fail") %>% count() %>% as.numeric()` failed the attention check. In the following analyses we will exclude these participants, leaving us with the following samples:

```{r}
d2 %>% count(country) %>% janitor::adorn_totals()
```


# Plots

We'll begin by plotting responses of "think(s)/thought" (red) vs. "believe(s)/believed" (turquoise) vs. other responses (gray) to get an overall sense of any patterns in the data.

```{r}
three_cols <- c("gray", gg_color_hue(2))
```

## By superordinate category

```{r, fig.width = 3, fig.asp = 0.5}
d2_long %>%
  left_join(sample_size_d2) %>%
  # ggplot(aes(x = super_cat, fill = response_cat3)) +
  ggplot(aes(x = super_cat, fill = responseX_cat3)) + # includes "does not X", "[adverb] X"
  facet_grid(. ~ country_n, scales = "free", space = "free") +
  geom_bar(position = "fill", #alpha = 0.7, 
           color = "black", size = 0.1) +
  geom_hline(yintercept = seq(0, 1, 0.25), lty = 1, size = 0.05) +
  scale_fill_manual(values = three_cols) +
  # scale_fill_viridis_d(begin = 0, end = 1, direction = -1, 
  #                      na.value = "gray95", option = "plasma") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
        legend.position = "top") +
  labs(x = "category", y = "proportion", fill = "response")
```

## By category

```{r, fig.width = 3, fig.asp = 0.5}
d2_long %>%
  left_join(sample_size_d2) %>%
  # ggplot(aes(x = category, fill = response_cat3)) +
  ggplot(aes(x = category, fill = responseX_cat3)) + # includes "does not X", "[adverb] X"
  facet_grid(. ~ country_n, scales = "free", space = "free") +
  geom_bar(position = "fill", #alpha = 0.7, 
           color = "black", size = 0.1) +
  geom_hline(yintercept = seq(0, 1, 0.25), lty = 1, size = 0.05) +
  scale_fill_manual(values = three_cols) +
  # scale_fill_viridis_d(begin = 0, end = 1, direction = 1, 
  #                      na.value = "gray95", option = "plasma") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
        legend.position = "top") +
  labs(x = "category", y = "proportion", fill = "response")
```

## By question

```{r, fig.width = 6, fig.asp = 0.7}
d2_long %>%
  left_join(sample_size_d2) %>%
  # ggplot(aes(x = reorder(str_wrap(question_text_short, 40), order), 
  #            fill = response_cat3)) +
  ggplot(aes(x = reorder(str_wrap(question_text_short, 40), order), 
             fill = responseX_cat3)) + # includes "does not X", "[adverb] X"
  facet_grid(country_n ~ category, scales = "free", space = "free") +
  geom_bar(position = "fill", #alpha = 0.7, 
           color = "black", size = 0.1) +
  geom_hline(yintercept = seq(0, 1, 0.25), lty = 1, size = 0.05) +
  scale_fill_manual(values = three_cols) +
  # scale_fill_viridis_d(begin = 0, end = 1, direction = 1, 
  #                      na.value = "gray95", option = "plasma") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
        legend.position = "top",
        plot.margin = (unit(c(0.2, 0.2, 0.2, 1.8), "cm"))) +
  labs(x = "category", y = "proportion", fill = "response")
```


# Analysis: without looking at preregistration

These analyses directly parallel the way we analyzed the Think Believe 1 data before looking at the preregistration. Again, we think these analyses are valuable because they're a little more efficient than the preregistered analyses -- no need for follow-up tests -- and they directly test the question of whether the effect of interest varies across countries/langauges.

As of 2020-01-22, we're now using the more lenient "believe\*" variable in these analyses.

Technical note: Unless specified otherwise, all of these analyses use "effect coding" for categorical variables (e.g., country, category of question) -- meaning that each country/langauge is compared to the "grand mean" collapsing across all countries/languages. Because of degrees of freedom issues, each analysis only compares 4 of the 5 countries to the grand mean -- by default, we've left out the comparison of the US/English to the grand mean, but stats for that comparison could easily be calculated (if we left out another country/language instead). This is just to say that you won't see statements like "The effect was exaggerated in the US relative to other countries," although they might be true.

## Analysis #1

First, we used a mixed effects logistic regression predicting how likely a participant was to write "believe" based on the superordinate category of the question ("religious" questions or "fact" questions), the country they were in/language they were using (US/English, Ghana/Fante, Thailand/Thai, China/Mandarin, or Vanuatu/Bislama), and an interaction between them, with a maximal random effects structure (random interpcepts and slopes by subject, and random intercepts by question). This analysis gives me a sense of (1) Whether participants were more likely to write "believe" for religious questions than fact questions, and whether this tendency varied by country/language, controlling for the fact that the overall rates of circling "believe" might vary by country/language (and accounting for individual differences and differences across individual questions).

Note that this analysis treats responses of "think" as the same as any other non-"believe" response.

```{r, echo = T}
r2.1 <- lmer(believeX ~ super_cat * country 
             + (1 + super_cat | thb2_subj) + (1 | question), 
             data = d2_long)
```

```{r}
regtab_fun(r2.1, std_beta = F) %>% regtab_style_fun(row_emph = c(2, 7:10))
```

```{r, include = F}
regtab_ran_fun(r2.1, subj_var = "thb2_subj") %>% regtab_style_fun()
```

**Take-away: The predicted effect is evident in this dataset, as it was in Think Believe 1. It appears to be exaggerated in China and diminished in Ghana and Vanuatu, a pattern which differs from Think Believe 1.**

```{r, include = F}
# re-code to get US vs. grand mean (drop Vanuatu instead of US)
r2.1a <- lmer(believeX ~ super_cat * country 
             + (1 + super_cat | thb2_subj) + (1 | question), 
             data = d2_long,
             contrasts = list(country = "contr.sum"))
```

```{r, include = F}
regtab_fun(r2.1a, std_beta = F) %>% regtab_style_fun(row_emph = c(2, 7:10))
```

## Analyses #1a-1e (by country)

Next, we did this same analysis within each country/langauge alone (using the most maximal random effect structure that converged across all countries/languages). 

```{r, echo = T}
# note: using most maximal common random effects structure
r2.1_us <- lmer(believeX ~ super_cat + 
                  # (1 + super_cat | thb2_subj) + (1 | question),
                  # (1 + super_cat || thb2_subj) + (1 | question), # failed to converge
                  (1 | thb2_subj) + (1 | question),
                  # (1 + super_cat | thb2_subj),
                  # (1 + super_cat || thb2_subj),
                  # (1 | thb2_subj),
                data = d2_long %>% filter(country == "US"))

r2.1_gh <- lmer(believeX ~ super_cat + 
                  # (1 + super_cat | thb2_subj) + (1 | question),
                  # (1 + super_cat || thb2_subj) + (1 | question),
                  (1 | thb2_subj) + (1 | question),
                  # (1 + super_cat | thb2_subj),
                  # (1 + super_cat || thb2_subj), 
                  # (1 | thb2_subj),
                data = d2_long %>% filter(country == "Ghana"))

r2.1_th <- lmer(believeX ~ super_cat + 
                  # (1 + super_cat | thb2_subj) + (1 | question), # failed to converge
                  # (1 + super_cat || thb2_subj) + (1 | question), # failed to converge
                  (1 | thb2_subj) + (1 | question),
                  # (1 + super_cat | thb2_subj),
                  # (1 + super_cat || thb2_subj), 
                  # (1 | thb2_subj),
                data = d2_long %>% filter(country == "Thailand"))

r2.1_ch <- lmer(believeX ~ super_cat + 
                  # (1 + super_cat | thb2_subj) + (1 | question),
                  # (1 + super_cat || thb2_subj) + (1 | question),
                  (1 | thb2_subj) + (1 | question), 
                  # (1 + super_cat | thb2_subj),
                  # (1 + super_cat || thb2_subj), 
                  # (1 | thb2_subj),
                data = d2_long %>% filter(country == "China"))

r2.1_vt <- lmer(believeX ~ super_cat + 
                  # (1 + super_cat | thb2_subj) + (1 | question),
                  # (1 + super_cat || thb2_subj) + (1 | question), # failed to converge
                  (1 | thb2_subj) + (1 | question),
                  # (1 + super_cat | thb2_subj),
                  # (1 + super_cat || thb2_subj), 
                  # (1 | thb2_subj),
                data = d2_long %>% filter(country == "Vanuatu"))
```

```{r}
bind_rows(regtab_fun(r2.1_us, std_beta = F) %>% mutate(Country = "US"),
          regtab_fun(r2.1_gh, std_beta = F) %>% mutate(Country = "Ghana"),
          regtab_fun(r2.1_th, std_beta = F) %>% mutate(Country = "Thailand"),
          regtab_fun(r2.1_ch, std_beta = F) %>% mutate(Country = "China"),
          regtab_fun(r2.1_vt, std_beta = F) %>% mutate(Country = "Vanuatu")) %>%
  select(Country, everything()) %>%
  regtab_style_fun(row_emph = seq(2, 10, 2)) %>%
  collapse_rows(1)
```

The effects of primary interest are in bold, and **the take-away is clear: In every country/language, participants were more likely to say "believe" in "religious" questions than in "fact" questions**.


## Analysis #2

In this analysis, we treated country/language as a random rather than fixed effect (with participants nested within countries). 

```{r, echo = T}
r2.2 <- lmer(believeX ~ super_cat 
             # + (1 + super_cat | country/thb2_subj) + (1 | question), # failed to converge
             # + (1 + super_cat || country/thb2_subj) + (1 | question), # failed to converge
             # + (1 + super_cat | country/thb2_subj), 
             # + (1 + super_cat || country/thb2_subj), # failed to converge
             + (1 | country/thb2_subj) + (1 | question), 
             # + (1 | country/thb2_subj), 
             data = d2_long)
```

```{r}
regtab_fun(r2.2) %>% regtab_style_fun(row_emph = 2)
```

```{r, include = F}
regtab_ran_fun(r2.2, subj_var = "thb2_subj") %>% regtab_style_fun()
```

The effect still holds.

## Analysis #3

Finally, we ran a version of this first model looking at 5 categories of questions (rather than 2 superordinate categories): Christian religious, Buddhist religious, well-known fact, esoteric fact, and personal fact. We compared these categories using planned orthogonal contrasts. 

```{r, echo = T}
r2.3 <- lmer(believe ~ category2 * country 
             # + (1 + category2 | thb2_subj) + (1 | question), # ranfx cor > 0.9
             # + (1 + category2 || thb2_subj) + (1 | question), # ranfx cor > 0.9
             # + (1 + category2 | thb2_subj), # ranfx cor > 0.9
             # + (1 + category2 || thb2_subj),
             + (1 | thb2_subj) + (1 | question), # match to study 1
             data = d2_long)
```

```{r}
regtab_fun(r2.3, std_beta = F,
           predictor_var1 = "category2_relig_fact", 
           predictor_name1 = "Contrast A",
           predictor_var2 = "category2_relig_local_other",
           predictor_name2 = "Contrast B",
           predictor_var3 = "category2_fact_WE_L",
           predictor_name3 = "Contrast C",
           predictor_var4 = "category2_fact_W_E",
           predictor_name4 = "Contrast D") %>% 
  regtab_style_fun(row_emph = c(2:5, 10:25)) # %>%
  # group_rows("Intercept", start_row = 1, end_row = 1) %>%
  # group_rows("Category comparisons", start_row = 2, end_row = 5) %>%
  # group_rows("Country comparisons", start_row = 6, end_row = 9) %>%
  # group_rows("Interactions: Ghana", start_row = 10, end_row = 13) %>%
  # group_rows("Interactions: Thailand", start_row = 14, end_row = 17) %>%
  # group_rows("Interactions: China", start_row = 18, end_row = 21) %>%
  # group_rows("Interactions: Vanuatu", start_row = 22, end_row = 25)
```

```{r, include = F}
regtab_ran_fun(r2.3, subj_var = "thb2_subj") %>% regtab_style_fun()
```

```{r, echo = T}
r2.3b <- lmer(believe ~ category2 * country 
             # + (1 + category2 | thb1_subj) + (1 | question), # failed to converge
             # + (1 + category2 || thb1_subj) + (1 | question), # failed to converge
             # + (1 + category2 | thb1_subj), # failed to converge
             # + (1 + category2 || thb1_subj),
             + (1 | thb2_subj) + (1 | question),
             contrasts = list(country = "contr.sum"),
             data = d2_long)
```

The first orthogonal contrast compared the two "religious" categories to the three "fact" categories ("Category (Religious vs. fact)"). This parallels the previous analyses, and the results are similar: Overall, participants were more likely to circle "believe" for religious questions than fact questions, and this tendency was diminished in Ghana and Vanuatu, and exaggerated in China.

The second orthogonal contrast compared local to other "religious" questions (crudely defining "local" as Christian for participants in the US, Ghana, and Vanuatu, and Buddhist for participants in Thailand and China). Overall, participants were more likely to circle "believe" for religious questions from a local religion, and this tendency was exaggerated in Vanuatu (a predominantly Christian samples) and diminished in China (an overwhelmingly non-religious sample).

The third orthogonal contrast compared well-known facts, on the one hand, to esoteric and personal facts, on the other. Overall, participants were no more or less likely to circle "believe" in either case.

The fourth orthogonal contrast compared esoteric to personal life facts. Overall, particpants were no more or less likely to circle "believe" in either case.

Note that these findings statistically control for differences across samples in the overall rate of circling "believe" (which was generally higher in Ghana and lower in Thailand).


# Analysis: Based on preregistration

From preregistration:

> "Survey 1: We will conduct a 5 (Site: China vs. Thailand vs. Vanuatu vs. Ghana vs. United States) x 2 (Statement Type: religion vs. fact) mixed ANOVA with repeated measures on the second factor and the proportion of trials on which participants completed sentences using a form the word “believe” (or its respective translation) as the dependent measure. To look for finer-grained differences between different religious and factual statements, we will also conduct a 5 (Site: China vs. Thailand vs. Vanuatu vs. Ghana vs. United States) x 5 (Statement Type: Buddhist religious statements vs. Christian religious statements vs. life facts vs. well-known facts vs. esoteric facts) mixed ANOVA with repeated measures on the second factor and the proportion of trials on which participants completed sentences using a form of the word “believe” (or its respective translation) as the dependent measure. In all cases where omnibus ANOVAs are significant, we will conduct pairwise analyses comparing each statement type with each other statement type and each site with each other site."

```{r, echo = T}
d2_anova <- d2_long %>%
  distinct(thb2_subj, country, super_cat, question, believeX) %>%
  group_by(thb2_subj, country, super_cat) %>%
  summarise(prop_believeX = mean(believeX)) %>%
  ungroup() %>%
  mutate(thb2_subj = factor(thb2_subj))

contrasts(d2_anova$country) <- contrast_country
contrasts(d2_anova$super_cat) <- contrast_super_cat
```

## Prereg Analysis #1

Here is the first preregistered analyis: a 5 (country) x 2 (question category) mixed ANOVA with repeated measures on the second factor and the proportion of trials on which participants wrote "berlieve" as the DV.

```{r, echo = T}
r2.4 <- d2_anova %>%
  anova_test(dv = "prop_believeX", 
             wid = "thb2_subj", 
             between = "country", 
             within = "super_cat",
             observed = "country")

get_anova_table(r2.4)
```

This analysis aligns with the regressions above and with Think Believe 1, suggesting that participants' tendency to write "believe" varied by country/language (`country`) and by question category (`super_cat`), and the difference between question category varied across countries/languages (i.e., there was an interaction: `country:super_cat`).

The preregistration indicated that we'd conduct pairwise follow-up analyses comparing the two question categories and comparing pairs of countires/languages -- but, again, we don't really think we're interested in comparing pairs of countries/languages, so we'll going to skip that for now. Instead, we'll compare the two questions categories within each country/language (to explore the significant interaction), as we did for Think Believe 1.

Follow-up analysis below.

### Comparing question categories

```{r, echo = T}
r2.5a <- t.test(prop_believeX ~ super_cat, paired = T, d2_anova); r2.5a
```

Collapsing across countries/languages, **participants wrote significantly more "believe" responses for questions in the religious category (`r 100 * (r2.5a$estimate[1] %>% round(2))`%) than they did for questions in the fact category (`r 100 * (r2.5a$estimate[2] %>% round(2))`%)**.

```{r}
d2_anova %>%
  group_by(country, super_cat) %>%
  summarise(mean_prop = mean(prop_believeX, na.rm = T)) %>%
  ungroup() %>%
  bind_rows(d2_long %>%
              group_by(country) %>%
              summarise(mean_prop = mean(believeX, na.rm = T)) %>%
              ungroup() %>%
              mutate(super_cat = "OVERALL")) %>%
  bind_rows(d2_anova %>%
              group_by(super_cat) %>%
              summarise(mean_prop = mean(prop_believeX, na.rm = T)) %>%
              ungroup() %>%
              mutate(country = "OVERALL")) %>%
  bind_rows(d2_anova %>%
              summarise(mean_prop = mean(prop_believeX, na.rm = T)) %>%
              ungroup() %>%
              mutate(super_cat = "OVERALL", country = "OVERALL")) %>%
  spread(super_cat, mean_prop) %>%
  select(country, OVERALL, religious, fact) %>%
  mutate(country = factor(country, levels = c(levels_country, "OVERALL"))) %>% 
  arrange(country) %>%
  janitor::adorn_rounding(2) %>%
  kable() %>%
  kable_styling()
```

### Comparing question categories within countries/languages

```{r, echo = T}
# US
r2.5b_us <- t.test(prop_believeX ~ super_cat, paired = T,
                   d2_anova %>% filter(country == "US")); r2.5b_us

# Ghana
r2.5b_gh <- t.test(prop_believeX ~ super_cat, paired = T,
                   d2_anova %>% filter(country == "Ghana")); r2.5b_gh


# Thailand
r2.5b_th <- t.test(prop_believeX ~ super_cat, paired = T,
                   d2_anova %>% filter(country == "Thailand")); r2.5b_th

# China
r2.5b_ch <- t.test(prop_believeX ~ super_cat, paired = T,
                   d2_anova %>% filter(country == "China")); r2.5b_ch

# Vanuatu
r2.5b_vt <- t.test(prop_believeX ~ super_cat, paired = T,
                   d2_anova %>% filter(country == "Vanuatu")); r2.5b_vt
```

**The difference between question categories was significant in each country/language considered alone.**

## Prereg Analysis #2

```{r, echo = T}
d2b_anova <- d2_long %>%
  distinct(thb2_subj, country, category, question, believeX) %>%
  group_by(thb2_subj, country, category) %>%
  summarise(prop_believeX = mean(believeX)) %>%
  ungroup() %>%
  mutate(thb2_subj = factor(thb2_subj))

contrasts(d2b_anova$country) <- contrast_country
contrasts(d2b_anova$category) <- contrast_category
```

Here is the second preregistered analyis: a 5 (country) x 5 (question sub-category) mixed ANOVA with repeated measures on the second factor and the proportion of trials on which participants included the word stem "believe" in their free respones as the DV.

```{r, echo = T}
r2.10 <- d2b_anova %>%
  anova_test(dv = "prop_believeX", 
             wid = "thb2_subj", 
             between = "country", 
             within = "category",
             observed = "country")

get_anova_table(r2.10)
```

This analysis aligns with the regressions above, suggesting that participants' tendency to use "believe" varied by country/language (`country`) and by question category (`category`), and the difference between question category varied across countries/languages (i.e., there was an interaction: `country:category`).

```{r}
d2b_anova %>%
  group_by(country, category) %>%
  summarise(mean_prop = mean(prop_believeX, na.rm = T)) %>%
  ungroup() %>%
  bind_rows(d2_long %>%
              group_by(country) %>%
              summarise(mean_prop = mean(believeX, na.rm = T)) %>%
              ungroup() %>%
              mutate(category = "OVERALL")) %>%
  bind_rows(d2b_anova %>%
              group_by(category) %>%
              summarise(mean_prop = mean(prop_believeX, na.rm = T)) %>%
              ungroup() %>%
              mutate(country = "OVERALL")) %>%
  bind_rows(d2b_anova %>%
              summarise(mean_prop = mean(prop_believeX, na.rm = T)) %>%
              ungroup() %>%
              mutate(category = "OVERALL", country = "OVERALL")) %>%
  spread(category, mean_prop) %>%
  select(country, OVERALL, `Christian religious`, `Buddhist religious`,
         `well-known fact`, `esoteric fact`, `life fact`) %>%
  mutate(country = factor(country, levels = c(levels_country, "OVERALL"))) %>% 
  arrange(country) %>%
  janitor::adorn_rounding(2) %>%
  kable() %>%
  kable_styling()
```


# Free response data

Here's a very quick pass at looking at the most common words/phrases in these free responses -- we did a quick and dirty "stemming" (converting, e.g., "believe" and "believes" and "believed" all to the stem "believ") but we could look into doing something more sophisticated. Here are the top 5 stems for each question category, by country: 

```{r, include = F}
d2_long %>%
  count(country, super_cat, category, response_lemma2) %>%
  arrange(country, super_cat, category, desc(n))
```

```{r}
d2_long %>%
  count(country, super_cat, category, response_lemma2) %>%
  arrange(country, super_cat, category, desc(n)) %>%
  group_by(country, super_cat, category) %>%
  mutate(percent = paste0(round(n/sum(n), 2) * 100, "%")) %>%
  top_n(5, n) %>%
  ungroup() %>%
  select(country, super_cat, category, response_lemma2, percent, n) %>%
  kable() %>%
  kable_styling() %>%
  collapse_rows(1:3)
```

There's lots to discuss here -- e.g., the common use of "know" (which is already of interest). Also, the Bislama data appears to be in Bislama (not translated) -- we've included "bilif" (and spelling variants) as "believe" and "ting" (as spelling variants) as "think" in all of the foregoing analyses.

```{r}
top_words <- d2_long %>%
  count(country, response_lemma2) %>%
  group_by(country) %>%
  mutate(prop = n/sum(n)) %>%
  top_n(6, prop) %>%
  ungroup() %>%
  group_by(response_lemma2) %>%
  summarise(n = sum(n),
            prop = sum(prop)/5) %>%
  ungroup() %>%
  arrange(desc(prop)) %>%
  mutate(order = 1:nrow(.))
```

```{r, fig.width = 6, fig.asp = 0.4, include = T}
four_cols2 <- c(gg_color_hue(2), "khaki", "gray")
d2_long %>%
  left_join(sample_size_d2) %>%
  filter(response_lemma2 %in% top_words$response_lemma2) %>%
  count(country_n, super_cat, #category, 
        response_lemma2) %>%
  complete(response_lemma2, nesting(country_n, super_cat), fill = list(n = 0)) %>%
  arrange(super_cat, #category, 
          country_n, desc(n)) %>%
  group_by(country_n, super_cat) %>% #, category) %>%
  mutate(proportion = round(n/sum(n), 2)) %>%
  ungroup() %>%
  mutate(response_lemma2 = reorder(response_lemma2, desc(n)),
         response_color = case_when(response_lemma2 == "think" ~ "think",
                                    response_lemma2 == "believe" ~ "believe",
                                    response_lemma2 == "know" ~ "know",
                                    TRUE ~ "other"),
         response_color = factor(response_color,
                                 levels = c("think", "believe", "know", 
                                            "other"))) %>%
  mutate(super_cat = recode_factor(super_cat,
                                   "religious" = "religious",
                                   "fact" = "matter-of-fact")) %>%
  left_join(top_words %>% select(response_lemma2, order)) %>%
  ggplot(aes(x = reorder(response_lemma2, order), 
             y = proportion, fill = response_color)) +
  facet_grid(super_cat ~ country_n) +
  geom_bar(stat = "identity", #alpha = 0.7, 
           color = "black", size = 0.1) +
  geom_hline(yintercept = seq(0, 1, 0.25), lty = 1, size = 0.05) +
  # scale_fill_manual(values = four_cols2) +
  scale_fill_viridis_d(begin = 0, end = 1, direction = 1, 
                       na.value = "gray95", option = "plasma") +
  scale_y_continuous(labels = scales::percent) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
        legend.position = "top") +
  labs(x = "Word stem", y = "Percent of responses", fill = "Response type")
ggsave("../figures/journal_submission/fig_2.eps")
```

```{r, fig.width = 6, fig.asp = 1, include = T}
four_cols2 <- c(gg_color_hue(2), "khaki", "gray")
d2_long %>%
  filter(response_lemma2 %in% top_words$response_lemma2) %>%
  count(country, category, #category, 
        response_lemma2) %>%
  complete(response_lemma2, nesting(country, category), fill = list(n = 0)) %>%
  arrange(category, #category, 
          country, desc(n)) %>%
  group_by(country, category) %>% #, category) %>%
  mutate(proportion = round(n/sum(n), 2)) %>%
  ungroup() %>%
  mutate(response_lemma2 = reorder(response_lemma2, desc(n)),
         response_color = case_when(response_lemma2 == "think" ~ "think",
                                    response_lemma2 == "believe" ~ "believe",
                                    response_lemma2 == "know" ~ "know",
                                    TRUE ~ "other"),
         response_color = factor(response_color,
                                 levels = c("think", "believe", "know", 
                                            "other"))) %>%
  mutate(category = recode_factor(
    category,
    "Christian religious" = "Christian religious",
    "Buddhist religious" = "Buddhist religious",
    "well-known fact" = "widely-known matter-of-fact",
    "esoteric fact" = "less widely-known matter-of-fact",
    "life fact" = "personal life matter-of-fact")) %>%
  left_join(top_words %>% select(response_lemma2, order)) %>%
  ggplot(aes(x = reorder(response_lemma2, order), 
             y = proportion, fill = response_color)) +
  facet_grid(category ~ country) +
  geom_bar(stat = "identity", #alpha = 0.7, 
           color = "black", size = 0.1) +
  geom_hline(yintercept = seq(0, 1, 0.25), lty = 1, size = 0.05) +
  # scale_fill_manual(values = four_cols2) +
  scale_fill_viridis_d(begin = 0, end = 1, direction = 1, 
                       na.value = "gray95", option = "plasma") +
  scale_y_continuous(labels = scales::percent) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
        legend.position = "top") +
  labs(x = "Word stem", y = "Percent of responses", fill = "Response type")
ggsave("../figures/journal_submission/fig_s2.eps")
```

```{r, fig.width = 6, fig.asp = 0.8}
d2_long %>%
  mutate(response_color = case_when(response_lemma2 == "think" ~ "think",
                                    response_lemma2 == "believe" ~ "believe",
                                    response_lemma2 == "know" ~ "know",
                                    TRUE ~ "other"),
         response_color = factor(response_color,
                                 levels = c("other", "know", "think", 
                                            "believe"))) %>%
  mutate(category = recode_factor(
    category,
    "Christian religious" = "Christian religious",
    "Buddhist religious" = "Buddhist religious",
    "well-known fact" = "widely-known matter-of-fact",
    "esoteric fact" = "less widely-known matter-of-fact",
    "life fact" = "personal life matter-of-fact")) %>%
  left_join(top_words %>% select(response_lemma2, order)) %>%
  ggplot(aes(x = reorder(str_wrap(question_text_short, 40), order), 
             fill = response_color)) +
  facet_grid(country ~ category, scales = "free", space = "free") +
  geom_bar(position = "fill", #alpha = 0.7, 
           color = "black", size = 0.2) +
  scale_y_continuous(labels = scales::percent) +
  scale_fill_manual(values = four_cols2[c(4:3, 1:2)]) +
  # scale_fill_viridis_d(begin = 0, end = 1, direction = -1, 
  #                      na.value = "gray95", option = "plasma") +
  geom_hline(yintercept = seq(0, 1, 0.25), lty = 1, size = 0.05) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
        legend.position = "top",
        plot.margin = (unit(c(0.2, 0.2, 0.2, 1.8), "cm"))) +
  labs(x = "Item", y = "Percent of responses", fill = "Response")
# ggsave("../figures/journal_submission/fig_s2.eps")
```

```{r}
write_csv(d2_long, "../data/thinkbelieve2_freeresponse_kw.csv")
```


# Demographics

```{r}
d2_demo <- d2 %>%
  select(country, thb2_subj, thb2_religion, starts_with("thb2_demo"))
```

```{r}
d2_demo %>%
  count(country)
```

```{r}
d2_demo %>%
  group_by(country) %>%
  summarise(min = min(thb2_demo_age, na.rm = T),
             max = max(thb2_demo_age, na.rm = T),
             mean = mean(thb2_demo_age, na.rm = T)) %>%
  mutate_at(vars(-country), ~round(., 2)) %>%
  ungroup()
```

```{r}
d2_demo %>%
  count(country, thb2_demo_sex) %>%
  group_by(country) %>%
  mutate(prop = round(n/sum(n, na.rm = T), 2)) %>%
  ungroup() %>%
  select(-n) %>%
  spread(thb2_demo_sex, prop)
```

```{r}
d2_demo %>%
  group_by(country) %>%
  summarise_at(vars(ends_with("_num")), mean, na.rm = T) %>%
  mutate_at(vars(-country), ~round(., 2)) %>%
  ungroup() %>%
  kable() %>% 
  kable_styling()
```


```{r}
d2_demo %>%
  count(country, thb2_demo_regp, thb2_religion) %>%
  group_by(country) %>%
  mutate(prop = round(n/sum(n, na.rm = T), 2)) %>%
  ungroup() %>%
  select(-n) %>%
  spread(thb2_demo_regp, prop)
```
