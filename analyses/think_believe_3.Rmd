---
title: "Think Believe 3 (forced choice, controlled content)"
output: 
  html_notebook:
    toc: true
    toc_float: true
---

```{r setup}
knitr::opts_chunk$set(echo = F, message = F)
```

In this notebook we analyze the first "think/believe" task, in which participants completed a series of closey matched fill-in-the-blanks by choosing between two options: "think" and "believe."


```{r}
source("./scripts/dependencies.R")
source("./scripts/custom_funs.R")
source("./scripts/var_recode_contrast.R")
```

```{r}
d3_raw <- read_xlsx("../data/ThinkBelieve3_organized.xlsx", sheet = "V1 & V2 no dupes") %>%
  # ensure no duplicates
  group_by(thb3_subj) %>%
  top_n(1, thb3_batc) %>% 
  ungroup() %>%
  mutate(thb3_ctry = factor(thb3_ctry, levels = levels_country))
```

```{r}
key3 <- read_xlsx("../data/ThinkBelieve3_organized.xlsx", sheet = 1)[1,] %>% 
  data.frame() %>%
  # get rid of extra qualtrics questions
  select(-c(StartDate:UserLanguage)) %>%
  t() %>% 
  data.frame() %>% 
  rownames_to_column("question") %>%
  rename(question_text = ".") %>%
  # get rid of white space
  mutate(question_text = gsub("\\s+", " ", question_text)) %>%
  # hand code question categories
  mutate(category = case_when(
    grepl("NASA", question_text) |
      grepl("medical school", question_text) |
      grepl("Astronomers", question_text) |
      grepl("reads history", question_text) |
      grepl("travels many places", question_text) ~ "scientific",
    grepl("Scientology", question_text) |
      grepl("God sent ten plagues", question_text) |
      grepl("holy man", question_text) |
      grepl("Mayan religion", question_text) |
      grepl("Church of Christ Scientist", question_text) ~ "religious",
    TRUE ~ NA_character_)) %>%
  mutate(category = factor(category, 
                           levels = c("religious", 
                                      "scientific")),
         super_cat = case_when(grepl("scientific", category) ~ "scientific",
                               grepl("religious", category) ~ "religious",
                               TRUE ~ NA_character_),
         super_cat = factor(super_cat, levels = c("religious", "scientific"))) %>%
  rownames_to_column("order") %>%
  mutate(order = as.numeric(order),
         question_text = gsub("‚Äô", "'", question_text),
         question_text_short = gsub("^.*that ", "...", question_text),
         var_name = names(d3_raw[names(d3_raw) != "thb3_version"]))
```

```{r}
d3 <- d3_raw %>%
  filter(thb3_ctry %in% levels_country) %>%
  mutate(thb3_ctry = factor(thb3_ctry, levels = levels_country))

contrasts(d3$thb3_ctry) = contrast_country
```

```{r}
d3_long <- d3 %>%
  gather(question, response, thb3_aliens.nasa:thb3_dog.wellwater) %>%
  mutate(think = ifelse(grepl("think", response) |
                          grepl("thought", response), T, F),
         believe = ifelse(grepl("belie", response), T, F),
         response_cat = case_when(believe == T ~ "believe",
                                  think == T ~ "think",
                                  TRUE ~ NA_character_),
         response_cat = factor(response_cat, levels = c("think", "believe"))) %>%
  left_join(key3 %>% select(-question) %>% rename(question = var_name))

contrasts(d3_long$thb3_ctry) = contrast_country
# contrasts(d3_long$category) = contrast_category
contrasts(d3_long$category) = contrast_super_cat # edit if needed later
contrasts(d3_long$super_cat) = contrast_super_cat
```

```{r}
# implement exclusion criteria and rename country variable
d3 <- d3 %>% 
  filter(thb3_ordr == "Yes", thb3_attn == "Pass") %>%
  rename(country = thb3_ctry)

d3_long <- d3_long %>% 
  filter(thb3_ordr == "Yes", thb3_attn == "Pass") %>%
  rename(country = thb3_ctry)
```


# Overview

From the preregistration ([link](https://aspredicted.org/p6iy3.pdf)):

> "Our overarching hypothesis for the present study is that [...] other languages will have an epistemic verb that is more likely to be used for religious attitude reports (similar to English “believe”) and a different epistemic verb that is more likely to be used for matter-of-fact attitude reports (similar to English “think”). 
> 
> For this study, we are examining five languages in five regions of interest: (i) Mandarin in China; (ii) Thai in Thailand; (iii) Bislama (an English-based creole
language) on the Melanesian Island of Vanuatu; (iv) Fante in Ghana; and (v) American English in the Bay Area, California. 
> 
> We thus have five more specific sub-hypotheses. For each of the first four languages / regions of interest, we hypothesize that a set of words or phrases exists whose usage parallels the difference between usage of “think” and “believe” in American English, with one word or phrase (the “think” analogue) being used for more matter-of-fact attitude reports and the other (the “believe” analogue) being more likely to be used for religious attitude reports. That gives us our first four sub-hypotheses: that Mandarin, Thai, Bislama and Fante speakers will each use two different words in a manner parallel to the use of
“think” and “believe” in an American English setting as identified by Heiphetz, Landers, and Van Leeuwen. Our fifth sub-hypothesis is that the Bay Area portion of the study will replicate the results of the earlier study of Heiphetz, Landers, and Van Leeuwen."


<p style="color:darkred">**KW EXECUTIVE SUMMARY (2020-01-20): We replicated the original finding in the US (and the findings of Think Believe 1 and 2): participants were more likely to circle "believe" for sentences in religious contexts than sentences in scientific contexts. We found the same pattern in four out of the five countries/langauges included in this study, with the exception of Ghana.**</p>

<p style="color:darkred">**As in previous studies, the pattern was weaker in Ghana/Fante than in other countries/languages -- indeed, it was not present. As in Think Believe 1 (but not Think Believe 2), the pattern was stronger in Thailand/Thai.**</p>


# Samples

Before we begin, it's important to note that we had unequal sample sizes by country:

```{r}
d3_raw %>% count(thb3_ctry)
```

However, `r d3_raw %>% filter(thb3_ordr == "No") %>% count() %>% as.numeric()` participants completed this task after completing other surveys, and an additional `r d3_raw %>% filter(thb3_ordr == "Yes", thb3_attn == "Fail") %>% count() %>% as.numeric()` failed the attention check. In the following analyses I will exclude these participants, leaving us with the following samples:

```{r}
d3 %>% count(country)
```

```{r}
sample_size_d3 <- d3 %>% 
  count(country) %>% 
  data.frame() %>%
  mutate(country_n = paste0(country, " (n=", n, ")"),
         country_n = reorder(country_n, as.numeric(country)))
```


# Plots

We'll begin by plotting responses of "think" (red) vs. "believe" (turquoise) to get an overall sense of any patterns in the data.

## By category

```{r, fig.width = 3, fig.asp = 0.5}
d3_long %>%
  left_join(sample_size_d3) %>%
  ggplot(aes(x = category, 
             # put NAs on top of bar
             fill = factor(response_cat,
                           levels = c(NA, "think", "believe"), 
                           exclude = NULL))) +
  facet_grid(. ~ country_n, scales = "free", space = "free") +
  geom_bar(position = "fill", alpha = 0.7, color = "black", size = 0.1) +
  # geom_hline(yintercept = 0.5, lty = 2) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
        legend.position = "top") +
  labs(x = "category", y = "proportion", fill = "response")
```

## By question

```{r, fig.width = 6, fig.asp = 0.7}
d3_long %>%
  left_join(sample_size_d3) %>%
  ggplot(aes(x = reorder(str_wrap(question_text_short, 40), order), 
             # put NAs on top of bar
             fill = factor(response_cat,
                           levels = c(NA, "think", "believe"), 
                           exclude = NULL))) +
  facet_grid(country_n ~ category, scales = "free", space = "free") +
  geom_bar(position = "fill", alpha = 0.7, color = "black", size = 0.1) +
  # geom_hline(yintercept = 0.5, lty = 2) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
        legend.position = "top",
        plot.margin = (unit(c(0.2, 0.2, 0.2, 1.8), "cm"))) +
  labs(x = "category", y = "proportion", fill = "response")
```


# Analysis: KW without looking at preregistration

Here's how I analyzed the data before looking at the preregistration. I think these analyses are valuable because they're a little more efficient than the preregistered analyses -- no need for follow-up tests -- and they directly test the question of whether the effect of interest varies across countries/langauges.

Technical note: Unless specified otherwise, all of these analyses use "effect coding" for categorical variables (e.g., country, category of question) -- meaning that each country/langauge is compared to the "grand mean" collapsing across all countries/languages. Because of degrees of freedom issues, each analysis only compares 4 of the 5 countries to the grand mean -- by default, I've left out the comparison of the US/English to the grand mean, but stats for that comparison could easily be calculated (if we left out another country/language instead). This is just to say that you won't see statements like "The effect was exaggerated in the US relative to other countries," although they might be true.

## KW Analysis #1

First, I used a mixed effects logistic regression predicting how likely a participant was to circle "believe" based on the superordinate category of the question ("religious" questions or "fact" questions), the country they were in/language they were using (US/English, Ghana/Fante, Thailand/Thai, China/Mandarin, or Vanuatu/Bislama), and an interaction between them, with a maximal random effects structure (random interpcepts and slopes by subject, and random intercepts by question). This analysis gives me a sense of (1) Whether participants were more likely to circle "believe" for religious questions than fact questions, and whether this tendency varied by country/language, controlling for the fact that the overall rates of circling "believe" might vary by country/language (and accounting for individual differences and differences across individual questions).

```{r, echo = T}
r3.1 <- lmer(believe ~ super_cat * country 
             # + (1 + super_cat | thb3_subj) + (1 | question), # failed to converge
             # + (1 + super_cat || thb3_subj) + (1 | question), # failed to converge
             # + (1 + super_cat | thb3_subj), # failed to converge
             # + (1 + super_cat || thb3_subj), # failed to converge
             + (1 | thb3_subj) + (1 | question),
             data = d3_long)
```

```{r}
regtab_fun(r3.1, std_beta = T) %>% regtab_style_fun(row_emph = c(2, 7:10))
```

```{r, include = F}
regtab_ran_fun(r3.1, subj_var = "thb3_subj") %>% regtab_style_fun()
```

The effects of primary interest are in bold:

- **Category (religious)**: Collapsing across countries/languages, participants were indeed more likely to say "believe" for "religious" questions, echoing Think Believe 1 and 2. 
- Country (Gh.): Participants in Ghana were generally more likely than other participants to say "believe," collapsing across question categories, echoing Think Believe 1 and 2
- Country (Th.): Participants in Thailand no more or less likely than other participants to say "believe," collapsing across question categories.
- Country (Ch.): Participants in China were no more or less likely than other participants to say "believe," collapsing across question categories.
- Country (Vt.): Participants in Vanuatu were no more or less likely than other participants to say "believe," collapsing across question categories.
- **Category (religious) x Country (Gh.)**: The difference in rates of "believe" responses between question categories was smaller in Ghana than in other countries, echoing Think Believe 1 and 2 -- in fact, in this study, it appears to have been reduced to zero (more on this below).
- **Category (religious) x Country (Th.)**: The difference in rates of "believe" responses between question categories was larger in Thailand than in other countries, echoing Think Believe 1 (but not Think Believe 2).
- **Category (religious) x Country (Ch.)**: The difference in rates of "believe" responses between question categories was no smaller or larger in China than in other countries.
- **Category (religious) x Country (Vt.)**: The difference in rates of "believe" responses between question categories was no smaller or larger in Vanuatu than in other countries.

**Take-away: The predicted effect is evident in this dataset. It appears to be exaggerated in Thailand and diminished in Ghana.**

## KW Analyses #1a-1e (by country)

Next, I did this same analysis within each country/langauge alone (using the most maximal random effect structure that converged across all countries/languages). 

```{r, echo = T}
# note: using most maximal common random effects structure
r3.1_us <- lmer(believe ~ super_cat + 
                  (1 + super_cat | thb3_subj) + (1 | question),
                # (1 + super_cat || thb3_subj) + (1 | question), # failed to converge
                # (1 | thb3_subj) + (1 | question),
                # (1 + super_cat | thb3_subj),
                data = d3_long %>% filter(country == "US"))

r3.1_gh <- lmer(believe ~ super_cat + 
                  (1 + super_cat | thb3_subj) + (1 | question),
                # (1 + super_cat || thb3_subj) + (1 | question), # failed to converge
                # (1 | thb3_subj) + (1 | question),
                # (1 + super_cat | thb3_subj),
                data = d3_long %>% filter(country == "Ghana"))

r3.1_th <- lmer(believe ~ super_cat + 
                  (1 + super_cat | thb3_subj) + (1 | question),
                # (1 + super_cat || thb3_subj) + (1 | question), # failed to converge
                # (1 | thb3_subj) + (1 | question),
                # (1 + super_cat | thb3_subj),
                data = d3_long %>% filter(country == "Thailand"))

r3.1_ch <- lmer(believe ~ super_cat + 
                  (1 + super_cat | thb3_subj) + (1 | question),
                # (1 + super_cat || thb3_subj) + (1 | question), # failed to converge
                # (1 | thb3_subj) + (1 | question),
                # (1 + super_cat | thb3_subj),
                data = d3_long %>% filter(country == "China"))

r3.1_vt <- lmer(believe ~ super_cat + 
                  (1 + super_cat | thb3_subj) + (1 | question), # failed to converge
                # (1 + super_cat || thb3_subj) + (1 | question),
                # (1 | thb3_subj) + (1 | question),
                # (1 + super_cat | thb3_subj),
                data = d3_long %>% filter(country == "Vanuatu"))
```

```{r}
bind_rows(regtab_fun(r3.1_us) %>% mutate(Country = "US"),
          regtab_fun(r3.1_gh) %>% mutate(Country = "Ghana"),
          regtab_fun(r3.1_th) %>% mutate(Country = "Thailand"),
          regtab_fun(r3.1_ch) %>% mutate(Country = "China"),
          regtab_fun(r3.1_vt) %>% mutate(Country = "Vanuatu")) %>%
  select(Country, everything()) %>%
  regtab_style_fun(row_emph = seq(2, 10, 2)) %>%
  collapse_rows(1)
```

The effects of primary interest are in bold, and **the take-away is fairly clear: In every country/language EXCEPT for Ghana/Fante, participants were more likely to say "believe" in "religious" questions than in "fact" questions**.


## KW Analysis #2

In this analysis, I treated country/language as a random rather than fixed effect (with participants nested within countries). (Note that I had to use a simpler random effects structure in order to get the model to converge.)

```{r, echo = T}
r3.2 <- lmer(believe ~ super_cat 
             + (1 + super_cat | country/thb3_subj) + (1 | question), 
             # + (1 + super_cat || country/thb3_subj) + (1 | question), # failed to converge
             # + (1 + super_cat | country/thb3_subj), # failed to converge
             # + (1 | country/thb3_subj) + (1 | question),
             data = d3_long)
```

```{r}
regtab_fun(r3.2) %>% regtab_style_fun(row_emph = 2)
```

```{r, include = F}
regtab_ran_fun(r3.2, subj_var = "thb3_subj") %>% regtab_style_fun()
```

The effect still holds.


# Analysis: Based on preregistration

From preregistration:

> "Survey 1: We will conduct a 5 (Site: China vs. Thailand vs. Vanuatu vs. Ghana vs. United States) x 2 (Statement Type: religion vs. fact) mixed ANOVA with repeated measures on the second factor and the proportion of trials on which participants completed sentences using a form the word “believe” (or its respective translation) as the dependent measure. To look for finer-grained differences between different religious and factual statements, we will also conduct a 5 (Site: China vs. Thailand vs. Vanuatu vs. Ghana vs. United States) x 5 (Statement Type: Buddhist religious statements vs. Christian religious statements vs. life facts vs. well-known facts vs. esoteric facts) mixed ANOVA with repeated measures on the second factor and the proportion of trials on which participants completed sentences using a form of the word “believe” (or its respective translation) as the dependent measure. In all cases where omnibus ANOVAs are significant, we will conduct pairwise analyses comparing each statement type with each other statement type and each site with each other site."

```{r, echo = T}
d3_anova <- d3_long %>%
  distinct(thb3_subj, country, super_cat, question, believe) %>%
  group_by(thb3_subj, country, super_cat) %>%
  summarise(prop_believe = mean(believe)) %>%
  ungroup() %>%
  mutate(thb3_subj = factor(thb3_subj))

contrasts(d3_anova$country) <- contrast_country
contrasts(d3_anova$super_cat) <- contrast_super_cat
```

## Prereg Analysis #1

Here is the first preregistered analyis: a 5 (country) x 2 (question category) mixed ANOVA with repeated measures on the second factor and the proportion of trials on which participants circled "berlieve" as the DV.

```{r, echo = T}
r3.4 <- d3_anova %>%
  anova_test(dv = prop_believe, 
             wid = thb3_subj, 
             between = country, 
             within = super_cat)

get_anova_table(r3.4)
```

This analysis aligns with the regressions above, suggesting that participants' tendency to circle "believe" varied by question category (`super_cat`) (though, in this analysis, *not* by country [`country`]), and the difference between question category varied across countries/languages (i.e., there was an interaction: `country:super_cat`).

The preregistration indicated that we'd conduct pairwise follow-up analyses comparing the two question categories and comparing pairs of countires/languages -- but, again, I don't really think we're interested in comparing pairs of countries/languages, so I'm going to skip that for now. Instead, I'll compare the two questions categories within each country/language (to explore the significant interaction).

Here we go:

### Comparing question categories

```{r, echo = T}
r3.5a <- t.test(prop_believe ~ super_cat, paired = T, d3_anova); r3.5a
```

Collapsing across countries/languages, **participants circled significantly more "believe" responses for questions in the religious category (`r 100 * (r3.5a$estimate[1] %>% round(2))`%) than they did for questions in the fact category (`r 100 * (r3.5a$estimate[2] %>% round(2))`%)**.

### Comparing question categories within countries/languages

```{r, echo = T}
# US
r3.5b_us <- t.test(prop_believe ~ super_cat, paired = T,
                   d3_anova %>% filter(country == "US")); r3.5b_us

# Ghana
r3.5b_gh <- t.test(prop_believe ~ super_cat, paired = T,
                   d3_anova %>% filter(country == "Ghana")); r3.5b_gh


# Thailand
r3.5b_th <- t.test(prop_believe ~ super_cat, paired = T,
                   d3_anova %>% filter(country == "Thailand")); r3.5b_th

# China
r3.5b_ch <- t.test(prop_believe ~ super_cat, paired = T,
                   d3_anova %>% filter(country == "China")); r3.5b_ch

# Vanuatu
r3.5b_vt <- t.test(prop_believe ~ super_cat, paired = T,
                   d3_anova %>% filter(country == "Vanuatu")); r3.5b_vt
```

**The difference between question categories was significant in each country/language considered alone, EXCEPT Ghana/Fante.**


