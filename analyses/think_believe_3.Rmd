---
title: "Think Believe 3 (forced choice, controlled content)"
output: 
  html_notebook:
    toc: true
    toc_float: true
---

```{r setup}
knitr::opts_chunk$set(echo = F, message = F)
```

In this notebook we analyze the third "think/believe" task, in which participants completed a series of closey matched fill-in-the-blanks by choosing between two options: "think" and "believe."

As of 2020-02-24, this file includes analysis of the new dataset collected in Ghana in Winter 2020 (a sample of English-speaking undergraduates).


```{r}
source("./scripts/dependencies.R")
source("./scripts/custom_funs.R")
source("./scripts/var_recode_contrast.R")
source("./scripts/data_prep.R")
```


# Overview

From the preregistration:

> "Our overarching hypothesis for the present study is that [...] other languages will have an epistemic verb that is more likely to be used for religious attitude reports (similar to English “believe”) and a different epistemic verb that is more likely to be used for matter-of-fact attitude reports (similar to English “think”). 
> 
> For this study, we are examining five languages in five regions of interest: (i) Mandarin in China; (ii) Thai in Thailand; (iii) Bislama (an English-based creole
language) on the Melanesian Island of Vanuatu; (iv) Fante in Ghana; and (v) American English in the Bay Area, California. 
> 
> We thus have five more specific sub-hypotheses. For each of the first four languages / regions of interest, we hypothesize that a set of words or phrases exists whose usage parallels the difference between usage of “think” and “believe” in American English, with one word or phrase (the “think” analogue) being used for more matter-of-fact attitude reports and the other (the “believe” analogue) being more likely to be used for religious attitude reports. That gives us our first four sub-hypotheses: that Mandarin, Thai, Bislama and Fante speakers will each use two different words in a manner parallel to the use of
“think” and “believe” in an American English setting as identified by Heiphetz, Landers, and Van Leeuwen. Our fifth sub-hypothesis is that the Bay Area portion of the study will replicate the results of the earlier study of Heiphetz, Landers, and Van Leeuwen."


<p style="color:darkred">**SUMMARY: We replicated the original finding in the US (and the findings of Think Believe 1 and 2): participants were more likely to circle "believe" for sentences in religious contexts than sentences in factual contexts. We found the same pattern in four out of the five countries/langauges included in this study, with the exception of Ghana.**</p>

<p style="color:darkred">**As in previous studies, the pattern was weaker in Ghana/Fante than in other countries/languages -- indeed, it was not present. As in Think Believe 1 (but not Think Believe 2), the pattern was stronger in Thailand/Thai.**</p>


# Samples

Before we begin, it's important to note that we had unequal sample sizes by country:

```{r}
d3_raw %>% count(thb3_ctry) %>% janitor::adorn_totals()
```

However, `r d3_raw %>% filter(thb3_ordr == "No") %>% count() %>% as.numeric()` participants completed this task after completing other surveys, and an additional `r d3_raw %>% filter(thb3_ordr == "Yes", thb3_attn == "Fail") %>% count() %>% as.numeric()` failed the attention check. In the following analyses we will exclude these participants, leaving us with the following samples:

```{r}
d3 %>% count(country) %>% janitor::adorn_totals()
```


# Plots

We'll begin by plotting responses of "think" (red) vs. "believe" (turquoise) to get an overall sense of any patterns in the data.

## By superordinate category

```{r, fig.width = 3, fig.asp = 0.6}
d3_long %>%
  left_join(sample_size_d3) %>%
  filter(country %in% levels_country) %>%
  mutate(country = factor(country, levels = levels_country)) %>%
  ggplot(aes(x = factor(super_cat, 
                        labels = c("religious", "matter-of-fact")), 
             # put NAs on top of bar
             fill = factor(response_cat,
                           levels = c(NA, "think", "believe"), 
                           exclude = NULL))) +
  facet_grid(. ~ country_n, scales = "free", space = "free") +
  geom_bar(position = "fill", #alpha = 0.7, 
           color = "black", size = 0.2) +
  scale_y_continuous(labels = scales::percent) +
  geom_hline(yintercept = seq(0, 1, 0.25), lty = 1, size = 0.05) +
  scale_fill_viridis_d(begin = 0, end = 0.4, direction = 1, 
                       na.value = "gray95", option = "plasma") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
        legend.position = "top") +
  labs(x = "Vignette context", y = "Percent of responses", fill = "Response")
ggsave("../figures/journal_submission/fig_3.eps")
```

## By question

```{r, fig.width = 4.5, fig.asp = 1.5}
d3_long %>%
  left_join(sample_size_d3) %>%
  # filter(country %in% levels_country) %>%
  # mutate(country = factor(country, levels = levels_country)) %>%
  mutate(super_cat = factor(super_cat, 
                            labels = c("religious", "matter-of-fact"))) %>%
  ggplot(aes(x = super_cat, 
             # put NAs on top of bar
             fill = factor(response_cat,
                           levels = c(NA, "think", "believe"), 
                           exclude = NULL))) +
  facet_grid(country_n ~ reorder(str_wrap(question_text_short, 25), order), 
             scales = "free", space = "free") +
  geom_bar(position = "fill", #alpha = 0.7, 
           color = "black", size = 0.2) +
  scale_y_continuous(labels = scales::percent) +
  geom_hline(yintercept = seq(0, 1, 0.25), lty = 1, size = 0.05) +
  scale_fill_viridis_d(begin = 0, end = 0.4, direction = 1, 
                       na.value = "gray95", option = "plasma") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
        legend.position = "top") +
  labs(x = "Vignette context", y = "Percent of responses", fill = "Response")
ggsave("../figures/journal_submission/fig_s3.eps")
```

# Analysis: without looking at preregistration

Here's how we analyzed the data before looking at the preregistration. We think these analyses are valuable because they're a little more efficient than the preregistered analyses -- no need for follow-up tests -- and they directly test the question of whether the effect of interest varies across countries/langauges.

Technical note: Unless specified otherwise, all of these analyses use "effect coding" for categorical variables (e.g., country, category of question) -- meaning that each country/langauge is compared to the "grand mean" collapsing across all countries/languages. Because of degrees of freedom issues, each analysis only compares 4 of the 5 countries to the grand mean -- by default, we've left out the comparison of the US/English to the grand mean, but stats for that comparison could easily be calculated (if we left out another country/language instead). This is just to say that you won't see statements like "The effect was exaggerated in the US relative to other countries," although they might be true.

## Analysis #1

First, we used a mixed effects logistic regression predicting how likely a participant was to circle "believe" based on the superordinate category of the question ("religious" questions or "fact" questions), the country they were in/language they were using (US/English, Ghana/Fante, Thailand/Thai, China/Mandarin, or Vanuatu/Bislama), and an interaction between them, with a maximal random effects structure (random interpcepts and slopes by subject, and random intercepts by question). This analysis gives me a sense of (1) Whether participants were more likely to circle "believe" for religious questions than fact questions, and whether this tendency varied by country/language, controlling for the fact that the overall rates of circling "believe" might vary by country/language (and accounting for individual differences and differences across individual questions).

```{r, echo = T}
r3.1 <- lmer(believe ~ super_cat * country 
             + (1 + super_cat | thb3_subj) + (1 | question), 
             data = d3_long %>%
               filter(country %in% levels_country),
             contrasts = list(country = contrast_country))
```

```{r}
regtab_fun(r3.1, std_beta = F) %>% regtab_style_fun(row_emph = c(2, 7:10))
```

```{r, include = F}
regtab_ran_fun(r3.1, subj_var = "thb3_subj") %>% regtab_style_fun()
```

**Take-away: The predicted effect is evident in this dataset. It appears to be exaggerated in Thailand and diminished in Ghana.**

```{r, include = F}
# re-code to get US vs. grand mean (drop Vanuatu instead of US)
r3.1a <- lmer(believe ~ super_cat * country 
             + (1 + super_cat | thb3_subj) + (1 | question), 
             data = d3_long %>%
               filter(country %in% levels_country),
             contrasts = list(country = "contr.sum"))
```

```{r, include = F}
regtab_fun(r3.1a, std_beta = F) %>% regtab_style_fun(row_emph = c(2, 7:10))
```

## Analyses #1a-1e (by country)

Next, we did this same analysis within each country/langauge alone (using the most maximal random effect structure that converged across all countries/languages). 

```{r, echo = T}
# note: using most maximal common random effects structure
r3.1_us <- lmer(believe ~ super_cat + 
                  # (1 + super_cat | thb3_subj) + (1 | question),
                  (1 | thb3_subj) + (1 | question), # to match gh2 and studies 1-2
                data = d3_long %>% filter(country == "US"))

r3.1_gh <- lmer(believe ~ super_cat + 
                  # (1 + super_cat | thb3_subj) + (1 | question),
                  (1 | thb3_subj) + (1 | question), # to match gh2 and studies 1-2
                data = d3_long %>% filter(country == "Ghana"))

r3.1_gh2 <- lmer(believe ~ super_cat +
                   # (1 + super_cat | thb3_subj) + (1 | question), # ranfx cor = 1
                   # (1 + super_cat || thb3_subj) + (1 | question), # ranfx cor = 1
                   (1 | thb3_subj) + (1 | question),
                 data = d3_long %>% filter(country == "Ghana (undergrads)"))

r3.1_th <- lmer(believe ~ super_cat + 
                  # (1 + super_cat | thb3_subj) + (1 | question),
                  (1 | thb3_subj) + (1 | question), # to match gh2 and studies 1-2
                data = d3_long %>% filter(country == "Thailand"))

r3.1_ch <- lmer(believe ~ super_cat + 
                  # (1 + super_cat | thb3_subj) + (1 | question),
                  (1 | thb3_subj) + (1 | question), # to match gh2 and studies 1-2
                data = d3_long %>% filter(country == "China"))

r3.1_vt <- lmer(believe ~ super_cat + 
                  # (1 + super_cat | thb3_subj) + (1 | question),
                  (1 | thb3_subj) + (1 | question), # to match gh2 and studies 1-2
                data = d3_long %>% filter(country == "Vanuatu"))
```

```{r}
bind_rows(regtab_fun(r3.1_us, std_beta = F) %>% mutate(Country = "US"),
          regtab_fun(r3.1_gh, std_beta = F) %>% mutate(Country = "Ghana"),
          regtab_fun(r3.1_gh2, std_beta = F) %>% mutate(Country = "Ghana (undergrads)"),
          regtab_fun(r3.1_th, std_beta = F) %>% mutate(Country = "Thailand"),
          regtab_fun(r3.1_ch, std_beta = F) %>% mutate(Country = "China"),
          regtab_fun(r3.1_vt, std_beta = F) %>% mutate(Country = "Vanuatu")) %>%
  select(Country, everything()) %>%
  regtab_style_fun(row_emph = seq(2, 12, 2)) %>%
  collapse_rows(1)
```

The effects of primary interest are in bold, and **the take-away is fairly clear: In every country/language EXCEPT for Ghana/Fante, participants were more likely to say "believe" in "religious" questions than in "fact" questions**. Frustratingly, the second sample from Ghana is kind of in between -- the effect is in the predicted direction, but the p-value is just shy of significance... but it's also a smaller sample than others.


## Analysis #2

In this analysis, we treated country/language as a random rather than fixed effect (with participants nested within countries). (Note that we had to use a simpler random effects structure in order to get the model to converge.)

```{r, echo = T}
r3.2 <- lmer(believe ~ super_cat 
             + (1 + super_cat | country/thb3_subj) + (1 | question),
             # + (1 + super_cat || country/thb3_subj) + (1 | question), # failed to converge
             # + (1 + super_cat | country/thb3_subj), # failed to converge
             # + (1 | country/thb3_subj) + (1 | question),
             data = d3_long)
```

```{r}
regtab_fun(r3.2) %>% regtab_style_fun(row_emph = 2)
```

```{r, include = F}
regtab_ran_fun(r3.2, subj_var = "thb3_subj") %>% regtab_style_fun()
```

The effect still holds.


# Analysis: Based on preregistration

From preregistration:

> "Survey 1: We will conduct a 5 (Site: China vs. Thailand vs. Vanuatu vs. Ghana vs. United States) x 2 (Statement Type: religion vs. fact) mixed ANOVA with repeated measures on the second factor and the proportion of trials on which participants completed sentences using a form the word “believe” (or its respective translation) as the dependent measure. To look for finer-grained differences between different religious and factual statements, we will also conduct a 5 (Site: China vs. Thailand vs. Vanuatu vs. Ghana vs. United States) x 5 (Statement Type: Buddhist religious statements vs. Christian religious statements vs. life facts vs. well-known facts vs. esoteric facts) mixed ANOVA with repeated measures on the second factor and the proportion of trials on which participants completed sentences using a form of the word “believe” (or its respective translation) as the dependent measure. In all cases where omnibus ANOVAs are significant, we will conduct pairwise analyses comparing each statement type with each other statement type and each site with each other site."

```{r, echo = T}
d3_anova <- d3_long %>%
  distinct(thb3_subj, country, super_cat, question, believe) %>%
  group_by(thb3_subj, country, super_cat) %>%
  summarise(prop_believe = mean(believe)) %>%
  ungroup() %>%
  mutate(thb3_subj = factor(thb3_subj))

contrasts(d3_anova$country) <- contrast_country6
contrasts(d3_anova$super_cat) <- contrast_super_cat
```

## Prereg Analysis #1

Here is the first preregistered analyis: a 5 (country) x 2 (question category) mixed ANOVA with repeated measures on the second factor and the proportion of trials on which participants circled "berlieve" as the DV.

```{r, echo = T}
r3.4 <- d3_anova %>%
  filter(country %in% levels_country) %>%
  mutate(country = factor(country, levels = levels_country)) %>%
  anova_test(dv = "prop_believe", 
             wid = "thb3_subj", 
             between = "country", 
             within = "super_cat",
             observed = "country")

get_anova_table(r3.4)
```

This analysis aligns with the regressions above, suggesting that participants' tendency to circle "believe" varied by question category (`super_cat`) (though, in this analysis, *not* by country [`country`]), and the difference between question category varied across countries/languages (i.e., there was an interaction: `country:super_cat`).

The preregistration indicated that we'd conduct pairwise follow-up analyses comparing the two question categories and comparing pairs of countires/languages -- but, again, we're not interested in comparing pairs of countries/languages, so we'll skip that for now. Instead, we'll compare the two questions categories within each country/language (to explore the significant interaction).

Follow-up analysis below.

### Comparing question categories

```{r, echo = T}
r3.5a <- t.test(prop_believe ~ super_cat, paired = T, 
                d3_anova %>%
                  filter(country %in% levels_country)); r3.5a
```

Collapsing across countries/languages, **participants circled significantly more "believe" responses for questions in the religious category (`r 100 * (r3.5a$estimate[1] %>% round(2))`%) than they did for questions in the fact category (`r 100 * (r3.5a$estimate[2] %>% round(2))`%)**.

```{r}
d3_anova %>%
  # filter(country %in% levels_country) %>%
  # mutate(country = factor(country, levels = levels_country)) %>%
  group_by(country, super_cat) %>%
  summarise(mean_prop = mean(prop_believe, na.rm = T)) %>%
  ungroup() %>%
  bind_rows(d3_long %>%
              # filter(country %in% levels_country) %>%
              # mutate(country = factor(country, levels = levels_country)) %>%
              group_by(country) %>%
              summarise(mean_prop = mean(believe, na.rm = T)) %>%
              ungroup() %>%
              mutate(super_cat = "OVERALL")) %>%
  bind_rows(d3_long %>%
              filter(country %in% levels_country) %>%
              # mutate(country = factor(country, levels = levels_country)) %>%
              group_by(super_cat) %>%
              summarise(mean_prop = mean(believe, na.rm = T)) %>%
              ungroup() %>%
              mutate(country = "OVERALL")) %>%
  bind_rows(d3_anova %>%
              # filter(country %in% levels_country) %>%
              # mutate(country = factor(country, levels = levels_country)) %>%
              summarise(mean_prop = mean(prop_believe, na.rm = T)) %>%
              ungroup() %>%
              mutate(super_cat = "OVERALL", country = "OVERALL")) %>%
  spread(super_cat, mean_prop) %>%
  select(country, OVERALL, religious, scientific) %>%
  mutate(country = factor(country, levels = c(levels_country6, "OVERALL"))) %>% 
  arrange(country) %>%
  janitor::adorn_rounding(2) %>%
  kable() %>%
  kable_styling()
```

### Comparing question categories within countries/languages

```{r, echo = T}
# US
r3.5b_us <- t.test(prop_believe ~ super_cat, paired = T,
                   d3_anova %>% filter(country == "US")); r3.5b_us

# Ghana
r3.5b_gh <- t.test(prop_believe ~ super_cat, paired = T,
                   d3_anova %>% filter(country == "Ghana")); r3.5b_gh

# Ghana (undergrads)
r3.5b_gh2 <- t.test(prop_believe ~ super_cat, paired = T,
                   d3_anova %>% filter(country == "Ghana (undergrads)")); r3.5b_gh2

# Thailand
r3.5b_th <- t.test(prop_believe ~ super_cat, paired = T,
                   d3_anova %>% filter(country == "Thailand")); r3.5b_th

# China
r3.5b_ch <- t.test(prop_believe ~ super_cat, paired = T,
                   d3_anova %>% filter(country == "China")); r3.5b_ch

# Vanuatu
r3.5b_vt <- t.test(prop_believe ~ super_cat, paired = T,
                   d3_anova %>% filter(country == "Vanuatu")); r3.5b_vt
```

**The difference between question categories was significant in each country/language considered alone, EXCEPT Ghana/Fante (first sample).**


# Demographics

```{r}
d3_demo <- d3 %>%
  select(country, thb3_subj, thb3_religion, starts_with("thb3_demo"))
```

```{r}
d3_demo %>%
  count(country)
```

```{r}
d3_demo %>%
  group_by(country) %>%
  summarise(min = min(thb3_demo_age, na.rm = T),
             max = max(thb3_demo_age, na.rm = T),
             mean = mean(thb3_demo_age, na.rm = T)) %>%
  mutate_at(vars(-country), ~round(., 2)) %>%
  ungroup()
```

```{r}
d3_demo %>%
  count(country, thb3_demo_sex) %>%
  group_by(country) %>%
  mutate(prop = round(n/sum(n, na.rm = T), 2)) %>%
  ungroup() %>%
  select(-n) %>%
  spread(thb3_demo_sex, prop)
```

```{r}
d3_demo %>%
  group_by(country) %>%
  summarise_at(vars(ends_with("_num")), mean, na.rm = T) %>%
  mutate_at(vars(-country), ~round(., 2)) %>%
  ungroup() %>%
  kable() %>% 
  kable_styling()
```


```{r}
d3_demo %>%
  count(country, thb3_demo_regp, thb3_religion) %>%
  group_by(country) %>%
  mutate(prop = round(n/sum(n, na.rm = T), 2)) %>%
  ungroup() %>%
  select(-n) %>%
  spread(thb3_demo_regp, prop)
```
